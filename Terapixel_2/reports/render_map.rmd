---
title: "render_map"
author: "Callum Simpson"
output:
  pdf_document: default
  word_document: default
  html_document:
  df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir= normalizePath('..'))

options(digits=2)
```


```{r include=FALSE}
# Load project

library('ProjectTemplate')
load.project()

source('src/Events_Explore_code.R')
source('src/render_map.R')

## An image of the render map
im <- load.image('D:/Masters/Cloud/Terapixel/Terapixel_v2/Terapixel_2/graphs/Capture3.PNG')

## just a blank square that is the same pixel size of the render map image
Square <- load.image('D:/Masters/Cloud/Terapixel/Terapixel_v2/Terapixel_2/graphs/Square.PNG')

## An image of the render map Color Quantization into 15 colours 
K15_map <- load.image('D:/Masters/Cloud/Terapixel/Terapixel_v2/Terapixel_2/graphs/K15_map.PNG')


```

In this report I will be investigating if there is any link between the time needed to render a tile and what is actually being rendered. The idea behind this was that if we can find similarities between tiles that have similar render times then it will give us an idea on how long it takes to render certain terrain. We could use this information to predict how long it would take to render a new image. We could also see what terrain types take the longest to render, with this information the render could be improved to help reduce the amount of time spent rendering these things.

## What excatly are we rendering in each title.

Whilst it may be complicated to do I want to find out if what we are rendering in each tile effects the rendering time. 

Using the data frame that I created that consisted of how long it took to complete each event in a task and combining that with the xy cords of each task, I mapped out the xy cords but but filling each tile with the amount of time it took to render.

The following is the cord map of how long it took to render that tile for the tasks in job lvl 12. 

```{r lvl12_render}

ggplot(render_with_cords %>% filter(level == 12), aes(x=x, y=y, fill= diff)) + 
 geom_tile() + facet_wrap(~ level,scales = "free") + scale_fill_gradient(low="grey", high="blue")  + ggtitle("Render time of each tile in Job 12")

```
Looking at the the resulting graph we can clearly see that there is shapes / patterns in the render time suggesting that what is being rendered does effect render time .If you where to compare this image to an image of the terapixle image you can clearly see what what some of the areas of the heat map relate too. Next we will need to find out what is being rendered in each tile.

Whilst I could write about what is in each tile by comparing it to a full image of the map created I wanted to do something better.

What I created was a system using cutimage that splits an image of the full render into tiles that allows me to filter out certain sections in a similar way in which I could filter out tiles in the heat map of rendertimes as seen above. This way we can see what each task in our data base was actually rendering and we could use that to visually compare tiles to see if there was any common ground between what was actually being rendered and how long it took.

## What is in each job lvl 8 tiles and can you group them on render time.

The following will be an investigation of the tiles done for the job level 8.

This is because ...
- a 16 by 16 grid of tiles is alot easier to do visual comparisons of tiles on than a large 256 by 256. (also visually showing how the image splits into 65536 tiles is a nightmare) 
- Also job 8 has a varied number of different render time that might tell us what we are wanting to know.

The following is and example of this. This is a full heat map for level 8

```{r lvl8_render_heat_map}

ggplot(render_with_cords %>% filter(level == 8), aes(x, y, fill= diff)) + 
 geom_tile() + facet_wrap(~ level,scales = "free") + scale_fill_gradient(low="grey", high="blue") + ggtitle("Render time of each tile in Job 8")

```

And this is the split map. So cord x = 0 and y = 0 in the heat map is 0 0 in this image.

```{r full_split}

base <- (render_with_cords %>% filter(jobId.x == "1024-lvl8-5ad819e1-fbf2-42e0-8f16-a3baca825a63"))$cord

cords_to_image(base,16,im)

```
looking at the image and the way the shadows are formed we can assume that the "sun" is south of the image.

## What tiles took the least amount of time to render

Looking at a summary of the render times of the tasks in lvl 8 we see that the minimum is 23 seconds.

```{r time_sumary_4}
time_sumary_8 %>% filter(eventName == "Render")
```

Because of that lets look at tiles that took less than 30 seconds to complete.

Plotting these tiles we see that they take place in the lower left coordinates (between x 0:2 and y 0:3). Plotting this out we see that these relate to tiles where the key about sensor information is placed. This is primarily a single flat color which is probably why it didn't take that long to render. 

```{r less_than_30_seconds}

ggplot(render_with_cords %>% filter(level == 8 , diff <= 30), aes(x, y, fill= diff)) + 
 geom_tile() + facet_wrap(~ level,scales = "free") + scale_fill_gradient(low="grey", high="blue")

base <- (render_with_cords %>% filter(level == 8, diff < 30))$cord

cords_to_image(base,16,im)

```

## 30 secounds to qt1  

We know that the qt1 time to render a task 8 tile was 40 seconds, so my next check was see what tiles had a render time that was less than 40 but greater than 30. 

It seems that the tiles that fell between this range are

- a large space of empty land 
- a section of water 
- a field next to the key with some trees
- a compacted section of city with alot of builds that all seem to be of the same size.
- a small section of houses

It seems that all these tiles seem to contain primarily 1 type of object to render (1 color) and/or comprised of objects that are all the same size.  

```{r 30_to_40_secounds }

ggplot(render_with_cords %>% filter(level == 8 ,  diff <= 40, diff > 30), aes(x, y, fill= diff)) + 
 geom_tile() + facet_wrap(~ level,scales = "free") + scale_fill_gradient(low="grey", high="blue")

base <- (render_with_cords %>% filter(level == 8, diff <= 40, diff > 30))$cord

cords_to_image(base,16,im)

```

## lower quartile to median 

The next logical step seemed to be from lower quartile to median. This will be 25% of the tiles.

we see that these tiles are

- Areas in which in which as flat but contain multiple colors.
- builds that is separated by a road
- shadows being rendered onto flat land.
- areas which are made up of trees.

```{r lower_quartile_to_median}

ggplot(render_with_cords %>% filter(level == 8 ,  diff <= 42, diff > 40), aes(x, y, fill= diff)) + 
 geom_tile() + facet_wrap(~ level,scales = "free") + scale_fill_gradient(low="grey", high="blue")

base <- (render_with_cords %>% filter(level == 8, diff <= 42, diff > 40))$cord

cords_to_image(base,16,im)

```

## median to upper quartile 

Next is the tiles that had a render time that falls between the median and the upper quartile.

- Alot of tiles that contain trees. 
- Flat areas that contain alot of extra details (i.e the tiling on the football stadiums roof).
- Highly compacted areas
- large areas of shadows


Comparing these tiles to the previous sets we see that these tiles seem to contain alot more details. This can range from just having alot of trees to having a little bits of extra details on parts of the building. 

```{r median_to_upper_quartile }

ggplot(render_with_cords %>% filter(level == 8 ,  diff <= 45, diff > 42), aes(x, y, fill= diff)) + 
 geom_tile() + facet_wrap(~ level,scales = "free") + scale_fill_gradient(low="grey", high="blue")

base <- (render_with_cords %>% filter(level == 8, diff <= 45, diff > 42))$cord

cords_to_image(base,16,im)

```

## upper quartile to maxium

Calculating the the maximum of Q3 + 1.5*IQR which is 52 seconds we will now view the tiles that had a render time between 45 seconds and 52 seconds. 

We see that these tiles contain 

- alot of trees
- areas of high detail (alot of small parts)
- Tall buildings casting shadows onto areas with alot of detail

```{r upper_quartile_to_maxium}

ggplot(render_with_cords %>% filter(level == 8 ,  diff <= 52, diff > 45), aes(x, y, fill= diff)) + 
 geom_tile() + facet_wrap(~ level,scales = "free") + scale_fill_gradient(low="grey", high="blue")

base <- (render_with_cords %>% filter(level == 8, diff <= 52, diff > 45))$cord

cords_to_image(base,16,im)

```

## Outliers

Finally we have the outliers. These tiles seem to be around the stadium.

Whilst its difficult to tell we see area where shadows are being cast onto areas that contain a high level of detail.

```{r Outliers}

ggplot(render_with_cords %>% filter(level == 8 ,diff > 52), aes(x, y, fill= diff)) + 
 geom_tile() + facet_wrap(~ level,scales = "free") + scale_fill_gradient(low="grey", high="blue")

base <- (render_with_cords %>% filter(level == 8, diff > 52))$cord

cords_to_image(base,16,im)

par(mfrow = c(1,1))

```


## Color Quantization

I wanted to see if we could work out a better way for working out what was being rendered that wasn't just looking at the tile and making a guess. We see that each object has a distinct color i.e grass is green, buildings are an off-white, roads are a greyish black so if we could "read" a tile and find the how dominant each color is we could use that to work out what that tile is.

To do this i created a bit of python code that would allow me to apply a K-means clustering algorithm to an image so that I could perform Color Quantization. Color Quantization is the process of reducing number of colors in an image, I wanted to do this to make classifying what is in a tile easier. 

Originally I was performing k means on each title to try and get the 3 dominate colours in each tile. I was going to use it to determine what was the majority color in each tile. This worked but due to things like shading in the original image and how each tile would be doing its own Color Quantization it would lead to each title identifying the same object but give it a slightly different RGB value making it difficult to classify pieces when all the tiles where put back together.

I instead decided to run Color Quantization on the full render map and then split that into tiles. I would then work out how many pixels of a certain color made up each tile image. By doing Color Quantization on the full render image It meant that the colors for certain objects would stay consistent through out each tile (i.e the blue in one tile would be the same RCB blue in another tile) 

I used K = 15 so I would have 15 different colors to work with. This is somewhat arbitrary but I chose a high number so hopefully we can fully capture certain  shadows and other little details. If we used a too low number of K then we will be grouping some objects together so detail would be lost and if we used a too high version of K it would make classification too difficult.

The following is the render map Color Quantization into 15 colors. This gave me the following image. 

https://docs.opencv.org/3.0-beta/doc/py_tutorials/py_ml/py_kmeans/py_kmeans_opencv/py_kmeans_opencv.html

```{r K15_map}

plot(K15_map)

cords_to_image(base,16,K15_map)

```

I will admit the there are a mistake with this image. It has grouped the dark shadows and roads together to the fact they where both really dark hues in the orginal image. Its has also turned the light blue in this image into roofs but as this blue only appeared in a small part of the graph I don't think It would cause any issues.

Now we need to discover what each color means / relates to.

At the moment we only have RGB values of the 15 colors so we will need to tidy it up a bit.

First there are some tiles that are made up of one color or a majority of one color, If we can work out the color that took up the most amount of pixels in a tile we can then determine what RGB value relates to what.

If we compare the dominate RGB values in each square to the tiles we can determine what some of the colours means.

 - key : (128,126,121) is grey

 - blank field (dirt) : (96,83,49) appears to be brown and takes up the majority of that blank area in the lower left.

 - Grass : (133,167,38) appears to be green and is dominate in areas with alot of grass

 - water: (13,0,149) is a blue and is dominant in the squares that are all blue

 - roofs: (192,183,143) is an off white that appears to be dominate tiles that contain alot off roof 


After that A bit of investigation had to be done to discover what the other colors mean. Please see Understanding Kmeans col for more details on this.
 
- inside of buildings : (237,234,210) an off white that seems to be used in text It looks like its needed to render the inside of buildings.

- DeepShadow_Roads : (23,26,13) black that is used in the shadows of trees, deep shadows and also roads.

- roof_details : (170,163,128) An off white but mainly used for extra details on the roof

- Roof_Slant_Away_Sun : (144,137,103) a dark beige white mainly seen as shadows on a roof. Mainly if a roof is not flat and is slanted, This colour seems to be used to repersent the side of a slanted roof that is not facing the sun.

- Orange : (220,88,37) used to represent the nodes.

- Roof_Slant_Face_Sun : (213,200,158) off white. Seems to be used in shadows in roof details. Looks like it is used on roofs that are slanted. This looks like the colour used on the side facing the sun

- Stone_ground : (156,130,125) an salmon color. Another set of flat area. Possibly tied to stone path / other walk ways.

- tree : (61,98,25) is a green, seems to be the front side of trees. 

- light_shadow : (54,56,40) a lightish black/grey. Seems to be used in shadows but a lighter shadow. So used to represent shadows transitioning from deep shadows to fully in light


- extra_shadows : (112,106,83) appears a bit in all sections. Seems to be used in shadows but at the very edge between something in shadows and being in the light

## The clean data

Doing a count by adding all the percentages for each group together we see that DeepShadow_Roads make up most of the image where as Inside_of_buildings makes up the least. 

```{r make_up}
colSums(job_8_Tiles_dom[,3:17])
```

We now know what each colors mean so we can work out the the dominate colour in each square. Plotting the cords of each image and filling with the dominate object we get the following.
```{r dominate}

ggplot(job_8_Tiles_dom, aes(x, y, fill= dominate)) + 
 geom_tile() + ggtitle("What is the dominate object in an tile")

```

Looking at the majority color in a tile we see that we have clumps of grass, dirt and roofs in a sea of tiles that are primary made up of roads/shadows. We also notice that out of 15 objects only 10 are dominate in a title suggests that the colors can be split into two groups.

- Used to represent something, i.e water and roofs
- used to represent details or shadows.

Next I will look at the summarize of the render times for each of the dominate tiles to see if there was any dominate feature that consistently caused a spike in render time.

```{r median_ob}

task_join_col %>%  group_by(dominate)  %>%  summarize(min = min(RENDER_TIME) , qt1 = quantile(RENDER_TIME, 1/4), median =  median(RENDER_TIME), qt3 = quantile(RENDER_TIME, 3/4), max =max(RENDER_TIME))

```

We noticed that the median render time differ for each of the dominate tiles.

It looks like tiles that are meant to represent and object have have a low render tiles and tiles that are domianted by what can be details (so roof details and Roof_Slant_Face_Sun) had a higher render time.

I will admit that Having roads and shadows being the same colour in the K 15 graph does hurt the effectiveness of this graph so another methods needs to be looked at so we can see how each Object types effects the rendering time, maybe something that barely appears in a tile actually greatly increases the amount of time needed to render said tile. 

## Correrlation

My next idea was to work out the correlation between each of the different objects and the render time. By doing this It would distinctly show if and how each of the different objects effected the amount of time needed to render each tile. The following is that correlation plot.

```{r corr}

ggcorrplot(cor(task_join_col %>% select(RENDER_TIME, roof,roof_details,Roof_Slant_Away_Sun,Grass,Dirt,Inside_of_buildings,Orange,Roof_Slant_Face_Sun,Stone_ground,Key,extra_shadows,tree,light_shadow,DeepShadow_Roads,water))
, hc.order = TRUE, type = "lower",  insig = "blank",
     outline.col = "white") + ggtitle("Correrlation between object types and render time")

```
We can get a lot from this graph but lets focus on the correlation between whats is being rendered and the time needed to render. 

We see that the more of flat objects that are not effected shadows and are fully in daylight (so Stone_ground, insides of building, the Key, grass and dirt) that appear in a tile then the quicker the that tile is to render.

We also see that the more that shadows appear (so Deep shadows, light shadows and extra shadows) in the tile then the longer that the tile takes to render (with quite a strong correlation).

Anything to do with roofs has caused an increase in render time.

Other bits of information that we can take away from this is that 

Trees seem to one of the main reasons for the shadows

Extra shadows seem to effect mainly roofs.

## What can we take away from this

We see that the more detailed a title is the longer the render time, we also see that areas that contain shadows/shade seem to increase the render time and that areas with a high density of trees seem to cause an issue.

The whole point of the terapixel image is to be detailed so removing detail to decrease the render time would against the whole point of this project.

Instead I believe that work should be done on the shadows / shading processes. It seems that all the tiles that visibly contain something casting a shadow or being in the shade cause the render time to increase. This might be due to the algorithm needed to create the shadows having to spend calculating how the shadow should fall onto the ground and how it should interact with whatever it touched. 

The fact that the shadows are causing an increase in render time tells us if we rendered an image where the sun was at sunset position (so causing longer shadows) then this would cause a increase in render time. On the flip side of this it suggest that the if the "sun" was positioned at mid day (so in the center of the graph) then we should have shorter render time.

Even if the algorithm needs to calculate shadows can be improved by a second or two then in the long run it would shave off a few minuets processing the fully rendered image. 


```{r colours}

#save_tiles(256)

```


https://www.r-bloggers.com/2019/01/extracting-colours-from-your-images-with-image-quantization/



http://blenditbayes.blogspot.com/2014/05/towards-yet-another-r-colour-palette.html
