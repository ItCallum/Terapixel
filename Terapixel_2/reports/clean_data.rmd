---
title: "clean_data"
author: "Callum Simpson"
date: "30/12/2020"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Clean data
This is my first look over the data to try and discover any issues that will need to take care of.

Note - This may not be as clean as my other reports and its not really meant to be a report its meant simply for me to gain a better understanding of the data. So it has been laid out so that its easy for me to gain insight.


## checkpoints_df
A file that contains application checkpoint events throughout the execution of the render job.

We See that we arn't missing data in any of the rows.
```{r cars}
checkpoints_df

sum(is.na(checkpoints_df))
```

### hostname

We have 1024 unique host names with the range of occurrence in the dataset being between 580 to 710. However looking at the boxplot the majority of the host names sit between 620 and 670.

```{r cars}
unique_Host <- count(checkpoints_df, checkpoints_df$hostname)
unique_Host

range((unique_Host)$n)

ggplot(unique_Host, aes(y=n)) + 
  geom_boxplot() +  
  theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank())

#test <- checkpoints_df
#test$hostname = substr(test$hostname,1,nchar(test$hostname)-2)

#test %>% count(hostname)

```
### eventType

Looking at eventType we see that both have the same number of occurrences. This is what we would expect as every event that starts must end.

```{r gpu_df}
count(checkpoints_df, checkpoints_df$eventType)
```

### eventName

Looking at eventName we see that both have the same number of occurrences. This suggests that every loop will have each event happening once (and also back up every event that starts also ends ). 

```{r gpu_df}
count(checkpoints_df, checkpoints_df$eventName)
```

### Date time

timestamp is a character so i changed it to a POSIXct time stamp then created two new columns date and time which is the time stamp split up.

Looking at it, it seems all this data occurred over 50ish minuets (07:41:30.957 to 08:30:16.345)

Whilist I probably wont use date in my investegation I did it to make sure that there where no errors in time recording (i.e a time belonding to a diffrent day appered in this test). Doing a count on Dates showed that all timestamp belong to 2018-11-08	

```{r Date_Time}
checkpoints_df 

min(checkpoints_df$timestamp) 

max(checkpoints_df$timestamp) 

checkpoints_df %>% group_by(date) %>% summarise(frequency = n())

```
### jobId

Looking at jobId we see that we have 3 job IDs. We know that each task had 10 events so by dividing the count of times that the jobId appeared in the data base and divided it by 10 we should set the number of task used to complete that job.

We see a majority of the tasks (99%) where done for level 12. Only 1 task (0.0015%) was needed to complete job level 4.

```{r jobId}
count(checkpoints_df, checkpoints_df$jobId) %>% mutate( task = n /10 , percent = n / sum(n) * 100)
```

### taskId

Each task is 4096 * 4096 pixels which are then split and subsampled as required into tiles. 

We see that each task appears 10 time (so the start and stop for each of the 5 events). By filtering the counts we see that there is no task with more or less than 10 records. 

```{r taskId}
taskId_count <- count(checkpoints_df, checkpoints_df$taskId) %>% mutate(percent = n / sum(n) * 100) 

taskId_count%>% filter(n > 10)

taskId_count%>% filter(n != 10)

```

## gpu_df

We have 1 million results regarding the virtual machine GPUS. Looking at it we dont have any rows missing any data. 


```{r gpu_df}
gpu_df

sum(is.na(checkpoints_df))
```

### Time stamp

The char timestamp was turned into a real timestamp and split into a separate date and time.

These recording are for about 50 minuets (07:41:25.772 to 08:31:53.573)

We see for each host name the time between records is 2 secounds. So 1 tick is 2 secounds 

```{r Date_Time}

gpu_df %>% filter(hostname == "8b6a0eebc87b4cb2b0539e81075191b9000009")

min(gpu_df$timestamp) 

max(gpu_df$timestamp) 
```

### gpuSerial

We have 1024 unique gpuSerial ids, by the looks of it there is no instance where an gpu is shared by by multiple virtual machines 

This tells us that each Virtual machine is paired to one physical GPU card.


```{r cars}
unique_Host <- count(gpu_df, gpu_df$gpuSerial)
unique_Host

range((unique_Host)$n)

summary((unique_Host)$n)

unique_Host %>% filter(n > 2000)


unique_serial_id <- gpu_df %>% group_by(gpuSerial) %>% count(hostname)

count(unique_serial_id) %>% filter(n > 1)
```

### hostname

Hostname is the host which the GPU is attched too.

We see that we have 1024 hosts in this df, We see that each host name occurs roughly 1500 times in this database however we have 5 host names that occur over double that amount of time.

these are hostname

0745914f4de046078517041d70b22fe7000005	3002			
35bd84d72aca403b8129a7d652cc2750000005	3000			
4a79b6d2616049edbf06c6aa58ab426a00000Y	2998			
4ad946d4435c42dabb5073531ea4f315000001	3000			
95b4ae6d890e4c46986d91d7ac4bf082000010	2991	

This will need to be investigated later, this may indicate the something has gone wrong 

```{r cars}
unique_Host <- count(gpu_df, gpu_df$hostname)
unique_Host

range((unique_Host)$n)

unique_Host %>% filter(n > 2000)

```

### powerDrawWatt

The Power draw of the GPU in watts. We see that there is quite the difference in 1st and 3rd quater(80 watts). Looking at the median is 96 watts per tick.

We also see that the max is 10 times the min

```{r powerDrawWatt}

summary(gpu_df$powerDrawWatt)

ggplot(gpu_df, aes(y=powerDrawWatt)) + 
  geom_boxplot() +  
  theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank())+ ggtitle("powerDrawWatt") 


```

### gpuUtilPerc

Percent utilization of the GPU Core(s).

We see that 25% of the time no core where used.

However we can see that the median is is 89 telling us that that over 50% of the time the Percent utilization of Gpu is over 89% (so very busy)

```{r gpuUtilPerc}

summary(gpu_df$gpuUtilPerc)

ggplot(gpu_df, aes(y=gpuUtilPerc)) + 
  geom_boxplot() +  
  theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank())+ ggtitle("gpuUtilPerc") 


```
### gpuTempC

The Temperature of the GPU in Celsius

Looking at the boxplot we see that the distribution of temperature seems almost normally distributed.

It seems that both mean and median is around the same - 40 degrees Celsius.

its seems the iqr range is 4. So 1st qu is 2 degrees less than the medium and 3rd Qu is 2 degrees above the median.
```{r gpuTempC}

summary(gpu_df$gpuTempC)

ggplot(gpu_df, aes(y=gpuTempC)) + 
  geom_boxplot() +  
  theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank())+ ggtitle("gpuTempC") 


```
### gpuMemUtilPerc

gpuMemUtilPerc is the Percent utilization of the GPU memory.

We see that the for 25% of the time no cores are being used. With median being 43% utilization

```{r gpuMemUtilPerc}

summary(gpu_df$gpuMemUtilPerc)

ggplot(gpu_df, aes(y=gpuMemUtilPerc)) + 
  geom_boxplot() +  
  theme(axis.title.x=element_blank(), axis.text.x=element_blank(), axis.ticks.x=element_blank())+ ggtitle("gpuMemUtilPerc") 


```

## xy_df
This file contains the x,y co-ordinates of which part the image was being rendered for each task.

we have 65,793 sets of coordinates 

Again we have no rows that contian any missing values

```{r xy_df}
xy_df

sum(is.na(xy_df))

```

### jobId

Looking at jobId we see that we have 3 job IDs. An overwhelming (99%) of the XY cords relate to Job level 12.  Only set of cords where for job lvl 4 (0.0015%).

This and the task id could probably be used to combined this and the application-checkpoints together.

```{r jobId}
count(xy_df, xy_df$jobId) %>% mutate(percent = n / sum(n) * 100)

xy_df %>% filter(level == 4)
xy_df %>% filter(level == 8)

```
### level

We have 3 different levels 4,8 and 12 (which relate to zoom ability).

The counts match the counts we got for job ID suggesting no error.

```{r level}
count(xy_df, xy_df$level) %>% mutate(percent = n / sum(n) * 100)
```

### X and Y 

All cords seem to be filled in for levels 8 and 12. This also can be used to understand the amount of task that where needed to visualize each level (as each cord set is a task)

```{r level}
df_heat_map 

ggplot(df_heat_map, aes(x, y, fill= V1)) + 
  geom_tile()+ 
  facet_wrap(~ level,scales = "free")

```
