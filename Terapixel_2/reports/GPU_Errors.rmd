---
title: "GPU_Errors"
author: "Callum Simpson"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(digits=2)
```

We have alot of GPUS which we depend on render the terapixel as the speed at which the image can get made depends on these GPUS.

If we where to have any GPUs that are problematic then they should be replaced in order to maximize efficiency. 

## The baseline

One of the ways that we could work out which GPUS are fault is by looking at GPUS that regularly completed tasks that took longer than the expected time

```{r baseline}

last_tasks %>% summarize(min = min(total_time) , qt1 = quantile(total_time, 1/4), mean = mean(total_time), median =  median(total_time), qt3 = quantile(total_time, 3/4), max =max(total_time), sums = sum(total_time))


last_tasks %>% group_by(jobId) %>% summarize(min = min(total_time) , qt1 = quantile(total_time, 1/4), mean = mean(total_time), median =  median(total_time), qt3 = quantile(total_time, 3/4), max =max(total_time), sums = sum(total_time))


```

## Find which CPUS are causing issues

From previous checks we know that the mean and median times needed to complete a full task was 43 seconds. 

By combing each task to a GPU by hostname and then linking the gpus by a time that was between when a task started and ended. (As I only wanted GPU serial and task time I removed the duplicated GPU and task listings so I have one instance of each task / gpu link)

We have 1024 gpus with each being used to complete 60-70 tasks each (mean is 64).

I believe that we could use this information to discover to find out which GPU potentially had processing issues by working out the the common amount of time that was needed to complete the task.

Looking at a count of medians we see that the highest median was 48 (with these GPUs have this median). The next set was 47 with 50 different GPU.

```{r  CPUS_median}

#link_gpu_task$gpuSerial <- as.character(link_gpu_task$gpuSerial)

#link_gpu_task %>% count(gpuSerial)  %>% summarize(min = min(n) , qt1 = quantile(n, 1/4), mean = mean(n), median =  median(n), qt3 = quantile(n, 3/4), max =max(n), sums = sum(n))

#link_gpu_task

link_gpu_task_table <- link_gpu_task %>% group_by(gpuSerial) %>% summarize(min = min(total_time) , qt1 = quantile(total_time, 1/4), mean = mean(total_time), median =  median(total_time), qt3 = quantile(total_time, 3/4), max =max(total_time), sums = sum(total_time))

#link_gpu_task_table %>% arrange(-sums)

link_gpu_task_table$median <-round(link_gpu_task_table$median, digits = 0)

link_gpu_task_table %>% count(median)

```

## Looking at the two gpus with 48 medians 

The two 48s where 323617042821 and 325117063019

Both of these only where used on a small number of tasks. This proably is due to the average task taking that long that each CPU may not have been able to do as much as the other gpus.

We see that all the tasks done on these gpu where for done for job 12. The mean time for the completion of tasks for these jobs where 43 secounds. 

As the lower qrt of this GPUS is 43 dose tell us that these GPUS are slower than the other GPUS. So these should be investigated for faults.

```{r median_48}

link_gpu_task$gpuSerial <- as.character(link_gpu_task$gpuSerial)

link_gpu_task_table %>% filter(median == 48)

#link_gpu_task %>% filter(gpuSerial == '323617042821')

#link_gpu_task %>% filter(gpuSerial == '325117063019')

#ggplot(link_gpu_task %>% filter(gpuSerial == '323617042821'), aes(y=total_time)) +  geom_boxplot()

#ggplot(link_gpu_task %>% filter(gpuSerial == '325117063019'), aes(y=total_time)) +  geom_boxplot()

```

## The maximum 

Maybe looking at the maximum time taken to complete each task.

When creating a count of each maximum time on each GPU we see the most common time max was between 60 to 68 seconds. This could be because these GPUs where used to work on tasks for job lvl 8 which we have seen take more time to processes. 

When looking at some of the more extreme max times we have 10 gpus which took more than 75 seconds to complete a task. 

Splitting this into a table we see that these GPUS all have higher means and medians than the baseline. 

```{r The_maximum}

link_gpu_task_table$max <-round(link_gpu_task_table$max, digits = 0)

#link_gpu_task_table %>% count(max)

link_gpu_task_table %>% filter(max >= 75)

```

## Looking at the job 

We saw previously that depending on the job the mean time to complete a task differs.

Its seems we have 257 out of the 1024 GPUs that have rendered tasks relating to 2 different jobs throughout the life time of the rendering the image.


```{r gpu}
link_gpu_task_table_job <- link_gpu_task %>% group_by(gpuSerial,jobId) %>% summarize(min = min(total_time) , qt1 = quantile(total_time, 1/4), mean = mean(total_time), median =  median(total_time), qt3 = quantile(total_time, 3/4), max =max(total_time), sums = sum(total_time))

link_gpu_task_table_job %>% count(gpuSerial) %>% filter(n > 1)

```

## Level 4

Job 4 only had one task in order for it to be fully completed. It took 52 seconds to complete. It would be interesting to see if this was due issues with the gpu or the complexity of the task needed to complete a level 4 job. 

We see that this task was done on gpuSerial 323617042759

Looking at gpuSerial 323617042759 we see that after the lvl 4 job its is used for tasks to finish lvl 12 jobs. When looking at the median times to complete its lvl 12 taks we see that the mean being 44 and the median is 46 seconds. While this is a bit on the slower side based on the the base line this arnt too far off suggesting that this gpu may not be that faulty, and that in fact lvl 4 task just took a bit longer.


```{r gpu}
## level 4
link_gpu_task_table_job %>% filter(jobId == '1024-lvl4-90b0c947-dcfc-4eea-a1ee-efe843b698df')

link_gpu_task %>% filter(gpuSerial == '323617042759')

link_gpu_task %>% filter(gpuSerial == '323617042759') %>% group_by(gpuSerial,jobId) %>% summarize(min = min(total_time) , qt1 = quantile(total_time, 1/4), mean = mean(total_time), median =  median(total_time), qt3 = quantile(total_time, 3/4), max =max(total_time), sums = sum(total_time))

```

## Level 8

We have 256 tasks used to render level 8 image.

We also seem to have 256 different GPUS that each ran a single Lvl 8 task.

We see that we have a few outliers for this job. There are 15 tasks that have been classed as outliers that go over the 65 seconds. The largest wait time is 94 seconds.

Looking at these

```{r gpu}
## level 4
link_gpu_task  %>% filter(jobId == '1024-lvl8-5ad819e1-fbf2-42e0-8f16-a3baca825a63') %>% count(gpuSerial)

level_8_link_gpu <- link_gpu_task %>% filter(jobId == '1024-lvl8-5ad819e1-fbf2-42e0-8f16-a3baca825a63') %>% group_by(gpuSerial) %>% summarize(min = min(total_time) , qt1 = quantile(total_time, 1/4), mean = mean(total_time), median =  median(total_time), qt3 = quantile(total_time, 3/4), max =max(total_time), sums = sum(total_time))

level_8_link_gpu$median <-round(level_8_link_gpu$median, digits = 0)

level_8_link_gpu %>% count(median) 

ggplot(link_gpu_task %>% filter(jobId == '1024-lvl8-5ad819e1-fbf2-42e0-8f16-a3baca825a63'), aes(y=total_time)) + 
  geom_boxplot()

level_8_link_gpu %>% filter(median > 65) 

link_gpu_task %>%  filter(gpuSerial == c('320118119482','323217056308','323217056545','323217056565','323617020175','323617020440','323617020967','324917052177','325017018696','325017020399','325117063092','325117172502','325117172559','325217086244')) 
#%>% summarize(min = min(total_time) , qt1 = quantile(total_time, 1/4), mean = mean(total_time), median =  median(total_time), qt3 = quantile(total_time, 3/4), max =max(total_time), sums = sum(total_time))
```

## the wait time

What might be interesting is to see how long it takes on average for each GPU to start a new task after the last one finished. If we could find GPUS that have a particularly long average time between completing each task then it might suggest something may be wrong with the GPU / Host.

By looking at all GPUS we see that the average time between tasks is 2.4 seconds. The could be used as a baseline that we could use to work out which GPUS may be a bit slow to start new task.

Looking at each individual gpuSerial medians We have 300 occurrences of those higher than 2.4 seconds, with 20 records having a median over 2.8 seconds. These may be worth looking at as if we find a reason that caused this longer delay we might be able to find a way to reduce wait time for all gpus.

```{r wait}

#link_gpu_task

link_gpu_task %>% group_by(gpuSerial) %>% mutate(idletime = lagtime - lag(timestamp.x)) %>%  na.omit(idletime) %>% ungroup() %>% summarize(min = min(idletime) , qt1 = quantile(idletime, 1/4), mean = mean(idletime), median =  median(idletime), qt3 = quantile(idletime, 3/4), max =max(idletime), sums = sum(idletime)) 


wait_table <- link_gpu_task %>% group_by(gpuSerial) %>% mutate(idletime = lagtime - lag(timestamp.x)) %>% arrange(gpuSerial) %>%  na.omit(idletime) %>% summarize(min = min(idletime) , qt1 = quantile(idletime, 1/4), mean = mean(idletime), median =  median(idletime), qt3 = quantile(idletime, 3/4), max =max(idletime), sums = sum(idletime)) %>%arrange(-median)

wait_table 

```

## The Heat map of time used to fully render each tile of the map may show us if there is any GPU issues.

When we plotted out the x y coordinates and the time taken to fully complete each task.

We notice that there is a few tasks that took a while to complete. Whats the most interesting is that there seems to be a a few rows in the low Y cords in the level 12 graph that all seem to have a unexpectedly high rendertimes. In the 12 level diagram we see a large square that all have relatively low rendertime but some of these cords form part of these odd rows of rendertime. We can see this more clearly if we reduce the y cords to 20.

I wanted to see what caused this as this dosn't seem that its has happened by chance. It does appear that something has gone wrong. 

With the median of the time to complete a job lvl 12 task being 43 median we see that the task in these rows take around 50+ seconds to complete.

In reduced data frame of y < 20 we have 912 records of the time to complete the task taking 50 + seconds(out of 3840 tasks),with one even taking 90+ seconds)

739 GPU where used to complete these 912 tasks.

```{r spefic_cord}

link_gpu_task_xy <- left_join(link_gpu_task, xy_df ,by = c("jobId","taskId") )

ggplot(link_gpu_task_xy, aes(x, y, fill= total_time)) + 
  geom_tile()+ 
  facet_wrap(~ level,scales = "free")+   scale_fill_gradient(low="grey", high="blue")


ggplot(link_gpu_task_xy %>% filter(level == 12 , y < 20, total_time > 50), aes(x, y, fill= total_time)) + 
  geom_tile() + scale_fill_gradient(low="grey", high="blue")

y_lessthan_15 <- link_gpu_task_xy %>% filter(level == 12 , y < 15, total_time > 50)

#y_lessthan_15$gpuSerial

#y_lessthan_15  %>% count(gpuSerial)

```
I wanted to find out if there was anything that these task shared in common. I felt that looking at the time timestamp would be a good start.

Looking at these tasks we see that near all of them start near the beginning of the whole processes (looking to be the within the first 5 set of tasks). This shows us that something has happened at the start of the processes that has caused these task to have a high time to complete the whole task.

```{r spefic_cord}

ggplot(y_lessthan_15, aes(x=timestamp.x, y=total_time)) +
  geom_point(size=2, shape=23)

```
We have one recorded record which as the time of 90+ seconds to fully complete the task. Whilist this a major outlier as no other tasks come near taking this long to complete it will be a good starting point for my analysis.

The 90 second task happens on gpuSerial 324917052381 doing taskId 76fb8e93-c3a6-456c-9661-3b7407800027 at time timestamp.x 2018-11-08 07:43:44.391

When we break down the events undertaken to complete taskId 76fb8e93-c3a6-456c-9661-3b7407800027 we see that something has went wrong and uploading as the uploading task took 42 seconds (the median for uploading is 1 second meaning that something has really gone wrong). This may be the common problem with all the these outlier tasks.

Plotting out the GPU timestamp and task time we see that the 90 time task is the 3rd task the GPU undertakes. Nothing other than the 90 time task stands out.

```{r spefic_cord}

y_lessthan_15 %>% filter(total_time > 89)

#times %>% filter(taskId == "76fb8e93-c3a6-456c-9661-3b7407800027") 

#link_gpu_task_xy %>%  filter(gpuSerial == "324917052381")

ggplot(link_gpu_task_xy %>%  filter(gpuSerial == "324917052381"), aes(x=timestamp.x, y=total_time)) +
  geom_point(size=2, shape=23)


```

We know that there might be something to do with the uploads.

Splitting the task down and mapping the upload time for the tasks over 50 seconds long. What we can see that is that we have alot of tasks that occur at the start of the whole process which have a 20* larger than the normal.
Doing a comparison with all the other tasks we see that the increase in upload time between 07:41:00 and 07:44:00. This "event" only occurs between this time suggesting that something happened at this point which caused the the uploads to increase by roughly 20 fold. 

```{r spefic_cord}
#y_lessthan_15
#y_lessthan_15 %>% count(gpuSerial)

#times %>% filter(taskId == y_lessthan_15$taskId ) 

Over50 <- y_lessthan_15$taskId

#Over50 

#subset(times,taskId %in% Over50) 


ggplot(subset(times %>% na.omit(times) %>% filter(jobId == "1024-lvl12-7e026be3-5fd0-48ee-b7d1-abd61f747705", eventName == "Uploading"),taskId %in% Over50) 
, aes(x=timestamp, y=diff)) +
  geom_point(size=2, shape=23)  + ggtitle("Upload times for the highlighted tasks")+ ylab("Upload time") + xlab("Time stamp")

ggplot(subset(times %>% na.omit(times) %>% filter(jobId == "1024-lvl12-7e026be3-5fd0-48ee-b7d1-abd61f747705", eventName == "Uploading"), !(taskId %in% Over50)) 
, aes(x=timestamp, y=diff)) +
  geom_point(size=2, shape=23)  + ggtitle("Upload times for all jobs 12")+ ylab("Upload time") + xlab("Time stamp")

```

Looking at the render time of these the y < 20 tasks we see that the render time does fall in line with other level 12 task suggesting the time to render hasnt been effected.

This tells us that the upload times the main reason these tasks have an upload time higher that the other tasks.

```{r could_it_be_run}
ggplot(subset(times %>% na.omit(times) %>% filter(jobId == "1024-lvl12-7e026be3-5fd0-48ee-b7d1-abd61f747705", eventName == "Render"),taskId %in% Over50) 
, aes(x=timestamp, y=diff)) +
  geom_point(size=2, shape=23)

ggplot(subset(times %>% na.omit(times) %>% filter(jobId == "1024-lvl12-7e026be3-5fd0-48ee-b7d1-abd61f747705" , eventName == "Render"), !(taskId %in% Over50)) 
, aes(x=timestamp, y=diff)) +
  geom_point(size=2, shape=23)

```

## What happened at job 8

After looking at job 12 and that there seemed to be some issues with tasks that happened at the start of the processes i decided to look at job lvl 8 as all these tasks happened within the same time frame that 

We see that there is a band similar of task time of around 65 seconds. We also see that there is 2 tasks that have the longest amount of time taken to complete a task.

These are ef15022d-f816-4434-b41e-709cb996bc08 and 83064f91-5a19-4526-8673-38ab28dd3ab7

```{r could_it_be_run}

ggplot(link_gpu_task_xy %>% filter(level == 8), aes(x, y, fill= total_time)) + 
  geom_tile() + scale_fill_gradient(low="grey", high="blue")

job_8 <- link_gpu_task_xy %>% filter(level == 8)

job_8 %>% filter(level == 8 & total_time > 75)
``` 

## The maximum job 8

Looking at the two tasks that gave us the longest times to complete a task (ef15022d-f816-4434-b41e-709cb996bc08 and 83064f91-5a19-4526-8673-38ab28dd3ab7).

Both events occurred at 07:43:44. We see that these tasks took 94 and 88 secounds. 

Breaking down these tasks we see that both have extremely high render times meaning that we are seeing the problem that occured in those lvl 12 jobs happen here.

```{r could_it_be_run}
job_8 %>% filter(level == 8 & total_time > 75)

times %>% filter(taskId == "ef15022d-f816-4434-b41e-709cb996bc08") 

times %>% filter(taskId == "83064f91-5a19-4526-8673-38ab28dd3ab7") 
``` 

## The band 

We can see a band of of high completion times in the Y 10 area. I wanted to see if this is because we are seeing the upload problem or something else.

Again we see that its an issue with uploading as the upload times in this band was around 20 secounds.

```{r could_it_be_run}

(job_8 %>% filter(level == 8 & y > 9 & y < 12))$taskId

the_band <- subset(times, taskId %in% (job_8 %>% filter(level == 8 & y > 9 & y < 12))$taskId)

the_band

the_band %>% group_by(taskId) %>% filter(eventName == "Uploading")

the_band %>% group_by(taskId) %>% filter(eventName == "Render")

``` 


## So what caused these high upload times.

By getting all the uploads that have a upload time of 15 seconds or higher I was able to started looking at these chases to try and find anything that could help explain these errors.

Through out the processes 1042 tasks had an uplaod time that was greater than 15

784 Gpus had a task that had an upload time of 15 seconds are higher

Looking at jobs we have 977 job 12 and 65 job 65.

Plotting the times at which these uploads occur we see that the overwheliming majority occur between 7:40:00 and 7:45:00.

Plotting the Hostnames and grouping them together we see that all hosts have been effected so it dosnt look like like it has anything to do with hardware.

By the looks of it the issue that caused this might be an outside factor that caused the error in upload time.

```{r could_it_be_run}

all_high_uploads <- times %>% na.omit(times) %>% filter(eventName == "Uploading", diff > 15)

all_high_uploads

X <- subset(link_gpu_task,taskId %in% all_high_uploads$taskId)

Y <- subset(link_gpu_task,gpuSerial %in% X$gpuSerial)

X  %>% count(gpuSerial)

all_high_uploads %>% count(jobId)

ggplot(all_high_uploads
, aes(x=timestamp, y=diff)) +
  geom_point()

all_high_uploads$hostname = substr(all_high_uploads$hostname,1,nchar(all_high_uploads$hostname)-2)
all_high_uploads %>% count(hostname)


```
